# BioAI Training Strategy Guide ðŸ§ 

**Version:** 0.0.2 (Alpha)

Wie wird ein BioAI-Agent schlau? Wir nutzen ein erweitertes **4-Ebenen-Modell**, das biologische Prinzipien mit technischer PrÃ¤zision vereint.

---

## Ebene 1: Instinkte (Injected Knowledge)
Angeborenes Wissen, das ab Sekunde 0 verfÃ¼gbar ist. Dies ist die Basis fÃ¼r Sicherheit ("Safety First").

* **Konzept:** Harte Regeln, die im LangzeitgedÃ¤chtnis (LTM) verankert sind.
* **Code:** `API_Teach(brain, input, action, 1.0f)`
* **Anwendung:**
    * **Sicherheit:** "Wenn Sensor > 100Â°C, dann NOT-AUS." (Gewicht 1.0 = Unverhandelbares Gesetz).
    * **Bias:** "Wenn du nicht weiter weiÃŸt, dreh dich nach rechts." (Gewicht 0.3 = Tendenz).

---

## Ebene 2: Erfahrung (Reinforcement Learning)
Lernen durch Versuch und Irrtum im laufenden Betrieb.

* **Konzept:** Der Agent probiert etwas aus. Basierend auf dem Ergebnis wird die Verbindung gestÃ¤rkt oder geschwÃ¤cht.
* **Code:** `API_Feedback(brain, reward, action)`
* **Prozess:**
    1.  Agent handelt (`API_Update`).
    2.  Sensor misst Ergebnis (z.B. "Temperatur gesunken").
    3.  System gibt Feedback:
        * **Positiv (+1.0):** Verbindung wird verstÃ¤rkt.
        * **Negativ (-1.0):** Verbindung wird gehemmt.
* **Speicher-Schutz:** BioAI nutzt ein KurzzeitgedÃ¤chtnis (STM). Nur wenn eine Erfahrung mehrfach bestÃ¤tigt wird (Consolidation Hits), wandert sie ins permanente GedÃ¤chtnis (LTM). Das verhindert das Lernen von ZufÃ¤llen ("Rauschen").

---

## Ebene 3: Imagination (Simulation & Planung) âœ¨ *Neu in v0.0.2*
Die FÃ¤higkeit, Konsequenzen vorherzusehen, bevor man handelt.

* **Konzept:** Der Agent nutzt sein gelerntes KausalitÃ¤ts-Wissen, um die Zukunft zu simulieren.
* **Code:** `API_Simulate(brain, inputs, count, depth)`
* **Anwendung:**
    * Ein Roboter steht vor einem Abgrund.
    * Statt zu springen (und zerstÃ¶rt zu werden), simuliert er den Sprung.
    * Ergebnis der Simulation: "Schmerz/Tod".
    * Entscheidung: Er bleibt stehen.
* **Vorteil:** ErmÃ¶glicht intelligentes Verhalten ohne teure Fehlversuche in der RealitÃ¤t.

---

## Ebene 4: Schwarm-Wissen (Social Propagation)


Wissen ist nicht an einen einzelnen Agenten gebunden.

* **Konzept:** Da `TokenID` (64-Bit Hash) universell ist, kÃ¶nnen Erfahrungen geteilt werden.
* **Mechanik:**
    * Agent A lernt: "Input X -> Aktion Y ist schlecht."
    * Agent A sendet `TokenID(X)` und `TokenID(Y)` an Agent B.
    * Agent B ruft `API_Teach(X, Y, -1.0)` auf.
* **Ergebnis:** Der gesamte Schwarm lernt aus dem Fehler eines einzelnen Individuums.

---


**BrainAI** - *Intelligence everywhere.*
Developed by **Sascha A. KÃ¶hne (winemp83)**
Product: **BioAI v0.0.2 (Alpha)**
ðŸ“§ [koehne83@googlemail.com](mailto:koehne83@googlemail.com)

Â© 2025 BrainAI / Sascha A. KÃ¶hne. All rights reserved.
