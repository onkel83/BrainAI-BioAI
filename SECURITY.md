# Sicherheitsrichtlinie (Security Policy) ğŸ›¡ï¸

BioAI wurde fÃ¼r **sicherheitskritische Edge-Anwendungen** (Industrielles IoT, Robotik, Smart Grids) entwickelt. Daher behandeln wir SicherheitslÃ¼cken nicht nur als Software-Fehler, sondern als potenzielle Risiken fÃ¼r die physische Sicherheit (Safety) von Mensch und Maschine.

## ğŸ›¡ï¸ UnterstÃ¼tzte Versionen

Wir unterstÃ¼tzen derzeit Sicherheits-Updates fÃ¼r die folgenden Versionen des BioAI Cores und der Wrapper:

| Version | UnterstÃ¼tzt | Anmerkungen |
| --- | --- | --- |
| **v0.7.6 (Industrial Closed Feature)** | âœ… | Aktueller stabiler Release |
| < 0.7.6 | âŒ | Veraltet (Deprecated). Nicht in der Produktion verwenden. |

---

## ğŸš¨ Meldung einer Schwachstelle

**ErÃ¶ffnen Sie KEINE Ã¶ffentlichen GitHub-Issues fÃ¼r SicherheitslÃ¼cken.**
Wenn Sie eine Schwachstelle entdeckt haben, welche die IntegritÃ¤t, Sicherheit oder VerfÃ¼gbarkeit eines Systems mit BioAI gefÃ¤hrden kÃ¶nnte, melden Sie diese bitte vertraulich.

### Vorgehensweise

Bitte senden Sie eine E-Mail an den leitenden Architekten:

* **E-Mail:** [koehne83@googlemail.com](mailto:koehne83@googlemail.com)
* **Betreff:** `[SECURITY] BioAI Vulnerability Report`

### Erforderliche Informationen

Bitte geben Sie so viele Details wie mÃ¶glich an:

1. **Komponente:** Betrifft es den *Open Source Wrapper* (C#/Python/Java/JS) oder den *proprietÃ¤ren C-Core* (`bioai.dll` / `.so`)?
2. **Schweregrad:** Kann die *Sicherheits-Reflex-Ebene* umgangen werden? Verursacht es einen Absturz (DoS)? KÃ¶nnen falsche Token injiziert werden?
3. **Proof of Concept (PoC):** Ein minimales Code-Beispiel, eine bÃ¶sartige Brain-Dump-Datei oder eine Beschreibung zur Reproduktion des Problems.

### Unser Reaktionsprozess

1. **EingangsbestÃ¤tigung:** Wir bestÃ¤tigen den Erhalt Ihrer Meldung innerhalb von 48 Stunden.
2. **Verifizierung:** Wir prÃ¼fen die Schwachstelle intern.
3. **Patching:**
* **Wrapper:** Wir verÃ¶ffentlichen umgehend einen Fix im Ã¶ffentlichen Repository.
* **Core:** Wir patchen die proprietÃ¤re Binary und verÃ¶ffentlichen eine neue Version (z. B. v0.7.6).


4. **Offenlegung:** Sobald der Patch fÃ¼r Kunden/Nutzer verfÃ¼gbar ist, werden wir Sie (falls gewÃ¼nscht) in den Release-Notes nennen.

---

## ğŸ”’ Spezifischer Sicherheitsumfang (Scope)

### 1. Der C-Core (Binary)

Der Core operiert im **Fixed Structure Mode** (kein `malloc`/`free` wÃ¤hrend der Laufzeit), um Angriffe auf die SpeicherintegritÃ¤t physikalisch auszuschlieÃŸen.

* **Kritisch:** Jede Methode, die einen **Buffer Overflow** (PufferÃ¼berlauf) oder ein **Memory Leak** im Core auslÃ¶st (insbesondere Ã¼ber `API_Deserialize`), wird als kritisch eingestuft.
* **Kritisch:** Jede Methode, die einen **ForceInstinct (Reflex)** umgeht, gilt als kritische Sicherheitsverletzung.
* **Hoch:** Das Brechen der **-Echtzeitgarantie** (z. B. durch Erzwingen einer Endlosschleife oder exzessiver Rechenzeit) stellt einen Denial-of-Service (DoS) gegen den physischen Regelkreis dar.

### 2. Die Wrapper (Source)

Die Wrapper bilden die Schnittstelle zwischen dem Betriebssystem und dem Core.

* **Hoch:** Schwachstellen, die eine **Token-Injektion** (VortÃ¤uschen von Sensordaten) Ã¼ber die API-Grenzen hinweg ermÃ¶glichen.
* **Mittel:** DLL-Hijacking-Schwachstellen im Lademechanismus der Bibliotheken.

---

## âš ï¸ Hinweis zu â€Safetyâ€œ vs. â€Securityâ€œ

BioAI unterscheidet zwischen **Safety** (Vermeidung von SchÃ¤den fÃ¼r die Umgebung) und **Security** (Schutz vor bÃ¶swilligem Zugriff).
In unserer Architektur fÃ¼hrt ein *Security*-Bruch (z. B. das Modifizieren der LTM-Gewichte durch einen Exploit) jedoch unmittelbar zu einem *Safety*-Risiko (z. B. ein Roboter ignoriert das Stopp-Signal).

**Wir behandeln alle Sicherheitsberichte mit hÃ¶chster PrioritÃ¤t.**

---

**BrainAI** - *-We don't need **BRUTEFORCE**, we know **Physiks**-*
Developed by **Sascha A. KÃ¶hne (winemp83)**
Product: **BioAI 0.7.6 (Industrial Closed Feature)**
ğŸ“§ [koehne83@googlemail.com](mailto:koehne83@googlemail.com)

&copy; 2025 BrainAI / Sascha A. KÃ¶hne. All rights reserved.
